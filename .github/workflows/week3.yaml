name: Week3 Coursewrok
# on: push
permissions:
  id-token: write
  contents: read
on:
  project:
    types: deleted
jobs:
  build-image-and-push:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4
      - uses: dorny/paths-filter@v2
        id: filter
        with:
          filters: |
            database:
              - 'database/seeding.sql'
            backend:
              - 'server/**'
            frontend:
              - 'client/**'

      - name: Login to Docker Hub
        uses: docker/login-action@v3
        if: steps.filter.outputs.database == 'true' || steps.filter.outputs.frontend == 'true' || steps.filter.outputs.backend == 'true'
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      # run only if 'database' files were changed
      - name: push database image
        if: steps.filter.outputs.database == 'true'
        run: |
          docker build -f Dockerfile.database -t susanssky/devops:cyf-hotel-database .
          docker push susanssky/devops:cyf-hotel-database

      # run only if 'frontend' files were changed
      - name: push frontend image
        if: steps.filter.outputs.frontend == 'true'
        run: |
          docker build -f Dockerfile.frontend -t susanssky/devops:cyf-hotel-frontend .
          docker push susanssky/devops:cyf-hotel-frontend

      # run if 'backend' or 'frontend' files were changed
      - name: push backend image
        if: steps.filter.outputs.backend == 'true'
        run: |
          docker build -f Dockerfile.backend -t susanssky/devops:cyf-hotel-backend .
          docker push susanssky/devops:cyf-hotel-backend
  # ----------------------------------------------------
  # Although matrix is also not bad, but the disadvantage is that once any file in the three folders is (minor) modified, the 3 docker images must be built and pushed to docker hub for the three folders, which is time-consuming.
  # build-image-and-push:
  #   runs-on: ubuntu-latest
  #   strategy:
  #     matrix:
  #       image: [database, backend, frontend]

  #   steps:
  #     - name: Checkout code
  #       uses: actions/checkout@v4

  #     - name: Docker Build
  #       run: docker build -f Dockerfile.${{ matrix.image }} -t susanssky/devops:cyf-hotel-${{ matrix.image }} .

  #     - name: Login to Docker Hub
  #       uses: docker/login-action@v3
  #       with:
  #         username: ${{ secrets.DOCKERHUB_USERNAME }}
  #         password: ${{ secrets.DOCKERHUB_TOKEN }}

  #     - name: Push Image
  #       run: docker push susanssky/devops:cyf-hotel-${{ matrix.image }}
  # ----------------------------------------------------
  ec2-deployment:
    needs: build-image-and-push
    runs-on: ubuntu-latest
    env:
      INSTANCE_ID: ${{ secrets.INSTANCE_ID }}
      PRIVATE_KEY: ${{ secrets.AWS_KEY_PAIR }}
      USER_NAME: ${{ secrets.EC2_USERNAME }}

      POSTGRES_DB: ${{ secrets.POSTGRES_DB }}
      POSTGRES_USER: ${{ secrets.POSTGRES_USER }}
      POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
      SERVER_PORT: 4000
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Install yq for grab services database name in docker-compose-week3.yaml
        run: |
          wget https://github.com/mikefarah/yq/releases/download/v4.12.1/yq_linux_amd64 -O /usr/local/bin/yq
          chmod +x /usr/local/bin/yq

      - name: Extract Services Data Name
        id: services-database-name
        run: |
          SERVICES=$(yq eval '.services | keys | .[0]' docker-compose-week3.yaml)
          echo "services=$SERVICES" >> $GITHUB_OUTPUT

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::503447358475:role/aws-gh-action
          aws-region: eu-west-2
      - name: extract ec2 state
        id: ec2-state
        run: |
          EC2_STATE=$(aws ec2 describe-instances --instance-ids ${INSTANCE_ID} --query 'Reservations[].Instances[].State.Name' --output text)
          echo "ec2_state=$EC2_STATE" >> $GITHUB_OUTPUT
      - name: If EC2 is running, don't start instances & wait until the instance is ok
        if: ${{ steps.ec2-state.outputs.ec2_state }} != 'running'
        run: |
          aws ec2 start-instances --instance-ids $INSTANCE_ID
          aws ec2 wait instance-status-ok --instance-ids $INSTANCE_ID

      - name: Get running instance public ip
        id: instance-public-ip
        run: |
          INSTANCE_PUBLIC_IP=$(aws ec2 describe-instances --instance-ids $INSTANCE_ID --query 'Reservations[*].Instances[*].PublicIpAddress' --output text)
          echo "instance_public_ip=$INSTANCE_PUBLIC_IP" >> $GITHUB_OUTPUT

      - name: Login with ssh & copy the docker-compose-week3.yaml to ec2 & docker-compose up
        # This EC2 instance must have Docker installed in advance.
        env:
          EC2_IP: ${{ steps.instance-public-ip.outputs.instance_public_ip }}
          DATABASE_HOSTNAME: ${{ steps.services-database-name.outputs.services }}
        run: |
          echo "$PRIVATE_KEY" > private_key
          chmod 600 private_key
          mkdir -p ~/.ssh
          cat >>~/.ssh/config << EOF
          Host ec2
            HostName $EC2_IP
            User $USER_NAME
            IdentityFile private_key
            StrictHostKeyChecking no
          EOF
          scp ./docker-compose-week3.yaml ec2:./
          ssh ec2 "POSTGRES_DB=${POSTGRES_DB} POSTGRES_USER=${POSTGRES_USER} \
          docker-compose -f docker-compose-week3.yaml pull && \
          POSTGRES_PASSWORD=${POSTGRES_PASSWORD} \
          SERVER_PORT=${SERVER_PORT} \
          DATABASE_URL=postgres://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DATABASE_HOSTNAME}:5432/${POSTGRES_DB}?sslmode=disable \
          VITE_SERVER_URL=http://${EC2_IP}:${SERVER_PORT} docker-compose -f docker-compose-week3.yaml up -d && \
          docker image prune -a -f"

# - name: stop instances
#   run: aws ec2 stop-instances --instance-ids $INSTANCE_ID
