name: Week4 Coursewrok
# on: push
permissions: # because use role-to-assume to login aws
  id-token: write
  contents: read
on:
  project:
    types: deleted
jobs:
  RDS_EC2:
    runs-on: ubuntu-latest
    outputs:
      rds-endpoint: ${{ steps.tf-outputs.outputs.RDS_ENDPOINT }}
      ec2-ip: ${{ steps.tf-outputs.outputs.EC2_IP }}
      ec2-id: ${{ steps.tf-outputs.outputs.EC2_ID }}
      ec2_private_key: ${{ steps.tf-outputs.outputs.EC2_PRIVATE_KEY }}
    steps:
      - uses: actions/checkout@v4
      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false # for get the terraform output value
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::503447358475:role/aws-gh-action
          aws-region: eu-west-2
      - name: Terraform command
        working-directory: ./terraform-week4/1-rds-ec2
        run: |
          terraform init
          terraform fmt -check
          terraform apply -auto-approve -var "database_username=${{ secrets.POSTGRES_USER }}" -var "database_password=${{ secrets.POSTGRES_PASSWORD }}" -var "docker_pw=${{ secrets.DOCKER_PW }}"
      - name: save the outputs value from tf to the outputs in this job
        id: tf-outputs
        working-directory: ./terraform-week4/1-rds-ec2
        run: |
          echo "RDS_ENDPOINT=$(terraform output -raw rds_endpoint)" >> $GITHUB_OUTPUT
          echo "EC2_IP=$(terraform output -raw ec2_public_ip)" >> $GITHUB_OUTPUT
          echo "EC2_ID=$(terraform output -raw ec2_id)" >> $GITHUB_OUTPUT
          EOF=$(dd if=/dev/urandom bs=15 count=1 status=none | base64)
          echo "EC2_PRIVATE_KEY<<$EOF" >> $GITHUB_OUTPUT
          echo "$(terraform output -raw ec2_private_key)" >> $GITHUB_OUTPUT
          echo "$EOF" >> $GITHUB_OUTPUT

  set-up-database-backend:
    needs: [RDS_EC2]
    runs-on: ubuntu-latest
    env:
      EC2_ID: ${{ needs.RDS_EC2.outputs.ec2-id }}
      EC2_IP: ${{ needs.RDS_EC2.outputs.ec2-ip }}
      PRIVATE_KEY: ${{ needs.RDS_EC2.outputs.ec2_private_key }}
      USER_NAME: ${{ secrets.EC2_USERNAME }}

      RDS_ENDPOINT: ${{  needs.RDS_EC2.outputs.rds-endpoint }}
      RDS_USER: ${{ secrets.POSTGRES_USER }}
      RDS_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
      SERVER_PORT: 4000
    steps:
      - uses: actions/checkout@v4
      - uses: docker/login-action@v3
        # v= if there is no update in 'backend' folder
        if: steps.filter.outputs.backend == 'true'
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      - name: push backend image to hub if there are any updadte in backend
        if: steps.filter.outputs.backend == 'true'
        run: |
          docker build -f Dockerfile.backend -t susanssky/devops:cyf-hotel-backend .
          docker push susanssky/devops:cyf-hotel-backend
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::503447358475:role/aws-gh-action
          aws-region: eu-west-2
      - name: Login with ssh & Import SQL Data & Docker-compose up
        run: |
          echo "$PRIVATE_KEY" > private_key
          chmod 600 private_key
          mkdir -p ~/.ssh
          cat >>~/.ssh/config << EOF
          Host ec2
            HostName $EC2_IP
            User $USER_NAME
            IdentityFile private_key
            StrictHostKeyChecking no
          EOF
          scp "./database/seeding.sql" ec2:./
          ssh ec2 "sudo -u postgres -i psql postgresql://${RDS_USER}:${RDS_PASSWORD}@$RDS_ENDPOINT < seeding.sql"
          ssh ec2 "rm seeding.sql"
          scp "./docker-compose-week4.yaml" ec2:./
          ssh ec2 "sudo docker-compose -f docker-compose-week4.yaml pull && \
          SERVER_PORT=${SERVER_PORT} \
          DATABASE_URL=postgres://${RDS_USER}:${RDS_PASSWORD}@${RDS_ENDPOINT}/ \
          sudo docker-compose -f docker-compose-week4.yaml pull && \
          docker-compose -f docker-compose-week4.yaml up -d && \
          docker image prune -a -f"

        # - name: stop instances
        #   run: aws ec2 stop-instances --instance-ids $EC2_ID
  set-up-frontend-and-run-tf:
    needs: [RDS_EC2, set-up-database-backend]
    runs-on: ubuntu-latest
    env:
      EC2_IP: ${{ needs.RDS_EC2.outputs.ec2-ip }}
      SERVER_PORT: 4000
    steps:
      - uses: actions/checkout@v4
      - name: 'Create env file'
        working-directory: ./client
        run: |
          echo "VITE_SERVER_URL=http://${EC2_IP}:${SERVER_PORT}" > .env
          cat .env
      - name: build static frontend website
        working-directory: ./client
        run: |
          npm ci
          npm run build
      - uses: hashicorp/setup-terraform@v3
        with:
          terraform_wrapper: false
      - uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::503447358475:role/aws-gh-action
          aws-region: eu-west-2
      - name: Terraform command
        working-directory: ./terraform-week4/2-s3
        run: |
          terraform init
          terraform fmt -check
          terraform apply -auto-approve
